{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b417927-bae9-4f7b-9a6f-c6285110f9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Starting grid search\n",
      "Evaluating: {'dropout': 0.3, 'momentum': 0.8, 'batch_size': 32, 'weight_decay': 0.0, 'lr_scheduler': 'noam'}\n",
      "Training fold 1/5...\n",
      "Training fold 2/5...\n",
      "Training fold 3/5...\n",
      "Training fold 4/5...\n",
      "Training fold 5/5...\n",
      "Avg Validation Accuracy: 82.59%\n",
      "Evaluating: {'dropout': 0.3, 'momentum': 0.8, 'batch_size': 32, 'weight_decay': 0.0, 'lr_scheduler': 'cosine'}\n",
      "Training fold 1/5...\n",
      "Training fold 2/5...\n",
      "Training fold 3/5...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 349\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m--> 349\u001b[0m     \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 331\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m()\u001b[0m\n\u001b[1;32m    328\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# Run grid search\u001b[39;00m\n\u001b[0;32m--> 331\u001b[0m best_params, results_df \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSimpleCNN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_folds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    334\u001b[0m execution_time \u001b[38;5;241m=\u001b[39m (end_time \u001b[38;5;241m-\u001b[39m start_time) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3600\u001b[39m  \u001b[38;5;66;03m# hours\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 177\u001b[0m, in \u001b[0;36mgrid_search\u001b[0;34m(dataset, model_fn, param_grid, k_folds, epochs)\u001b[0m\n\u001b[1;32m    167\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m'\u001b[39m: dropout,\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmomentum\u001b[39m\u001b[38;5;124m'\u001b[39m: momentum,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr_scheduler\u001b[39m\u001b[38;5;124m'\u001b[39m: lr_scheduler\n\u001b[1;32m    173\u001b[0m }\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 177\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_folds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m avg_val_acc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([results[fold][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k_folds)])\n\u001b[1;32m    180\u001b[0m avg_train_acc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([results[fold][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k_folds)])\n",
      "Cell \u001b[0;32mIn[1], line 141\u001b[0m, in \u001b[0;36mcross_validate_model\u001b[0;34m(dataset, model_fn, params, k_folds, epochs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m         scheduler_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m step, T, T0: cosine_lr_schedule(step, eta_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, T\u001b[38;5;241m=\u001b[39mT, T0\u001b[38;5;241m=\u001b[39mT0)\n\u001b[0;32m--> 141\u001b[0m     train_acc, train_loss, val_acc, val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     results[fold] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m'\u001b[39m: train_acc,\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: train_loss,\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m: val_acc,\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: val_loss\n\u001b[1;32m    150\u001b[0m     }\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "Cell \u001b[0;32mIn[1], line 74\u001b[0m, in \u001b[0;36mtrain_and_validate\u001b[0;34m(train_loader, val_loader, model, optimizer, scheduler_fn, epochs)\u001b[0m\n\u001b[1;32m     71\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     72\u001b[0m running_loss, correct, total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     75\u001b[0m     global_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     76\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/datasets/mnist.py:146\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    143\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/transforms/transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/transforms/functional.py:350\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/transforms/_functional_tensor.py:922\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    920\u001b[0m mean \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(mean, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    921\u001b[0m std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(std, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd evaluated to zero after conversion to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, leading to division by zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mean\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Create plots directory if it doesn't exist\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "\n",
    "print(\"Loading data\")\n",
    "\n",
    "# Load the FashionMNIST data\n",
    "def get_fashionmnist_data():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    return dataset\n",
    "\n",
    "# Define the Simple CNN Model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 7 * 7, 128), nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Noam Learning Rate Scheduler\n",
    "def noam_lr_schedule(step, d_model=512, warmup=4000):\n",
    "    return d_model ** -0.5 * min(step ** -0.5, step * warmup ** -1.5)\n",
    "\n",
    "# Cosine Learning Rate Scheduler\n",
    "def cosine_lr_schedule(t, eta_max, T, T0):\n",
    "    if t <= T0:\n",
    "        return 1e-4 + (eta_max - 1e-4) * (t / T0)\n",
    "    return eta_max * np.cos((math.pi / 2) * ((t - T0) / (T - T0))) + 1e-6\n",
    "\n",
    "# Train and Validate the Model\n",
    "def train_and_validate(train_loader, val_loader, model, optimizer, scheduler_fn, epochs=5):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_acc, val_acc = [], []\n",
    "    train_loss, val_loss = [], []\n",
    "    global_step = 0\n",
    "    T = epochs * len(train_loader)\n",
    "    T0 = T // 5\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0, 0, 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            global_step += 1\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # LR scheduling\n",
    "            lr = scheduler_fn(global_step, T, T0)\n",
    "            optimizer.param_groups[0]['lr'] = lr\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        train_acc.append(100 * correct / total)\n",
    "        train_loss.append(running_loss / len(train_loader))\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss_epoch, correct, total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss_epoch += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        val_acc.append(100 * correct / total)\n",
    "        val_loss.append(val_loss_epoch / len(val_loader))\n",
    "\n",
    "    return train_acc, train_loss, val_acc, val_loss\n",
    "\n",
    "# Cross-validation for hyperparameter tuning\n",
    "def cross_validate_model(dataset, model_fn, params, k_folds=5, epochs=5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "    results = {}\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "        print(f\"Training fold {fold+1}/{k_folds}...\")\n",
    "\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "\n",
    "        # Use more workers for faster data loading if available\n",
    "        num_workers = 4 if torch.cuda.is_available() else 0\n",
    "        train_loader = DataLoader(train_subset, batch_size=params['batch_size'], shuffle=True, \n",
    "                                 num_workers=num_workers, pin_memory=True if torch.cuda.is_available() else False)\n",
    "        val_loader = DataLoader(val_subset, batch_size=params['batch_size'], shuffle=False,\n",
    "                               num_workers=num_workers, pin_memory=True if torch.cuda.is_available() else False)\n",
    "\n",
    "        model = model_fn(dropout=params['dropout']).to(device)\n",
    "        optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=params['momentum'], weight_decay=params['weight_decay'])\n",
    "\n",
    "        if params['lr_scheduler'] == 'noam':\n",
    "            scheduler_fn = lambda step, *_: noam_lr_schedule(step)\n",
    "        else:\n",
    "            scheduler_fn = lambda step, T, T0: cosine_lr_schedule(step, eta_max=0.1, T=T, T0=T0)\n",
    "\n",
    "        train_acc, train_loss, val_acc, val_loss = train_and_validate(\n",
    "            train_loader, val_loader, model, optimizer, scheduler_fn, epochs\n",
    "        )\n",
    "\n",
    "        results[fold] = {\n",
    "            'train_acc': train_acc,\n",
    "            'train_loss': train_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'val_loss': val_loss\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "# Grid Search with Batch Size and Other Parameters\n",
    "def grid_search(dataset, model_fn, param_grid, k_folds=5, epochs=5):\n",
    "    best_params = None\n",
    "    best_val_acc = 0\n",
    "\n",
    "    # Create a list to store all results for visualization\n",
    "    results_data = []\n",
    "\n",
    "    for dropout in param_grid['dropout']:\n",
    "        for momentum in param_grid['momentum']:\n",
    "            for batch_size in param_grid['batch_size']:\n",
    "                for weight_decay in param_grid['weight_decay']:\n",
    "                    for lr_scheduler in param_grid['lr_scheduler']:\n",
    "                        params = {\n",
    "                            'dropout': dropout,\n",
    "                            'momentum': momentum,\n",
    "                            'batch_size': batch_size,\n",
    "                            'weight_decay': weight_decay,\n",
    "                            'lr_scheduler': lr_scheduler\n",
    "                        }\n",
    "\n",
    "                        print(f\"Evaluating: {params}\")\n",
    "\n",
    "                        results = cross_validate_model(dataset, model_fn, params, k_folds, epochs)\n",
    "\n",
    "                        avg_val_acc = np.mean([results[fold]['val_acc'][-1] for fold in range(k_folds)])\n",
    "                        avg_train_acc = np.mean([results[fold]['train_acc'][-1] for fold in range(k_folds)])\n",
    "                        avg_train_loss = np.mean([results[fold]['train_loss'][-1] for fold in range(k_folds)])\n",
    "                        avg_val_loss = np.mean([results[fold]['val_loss'][-1] for fold in range(k_folds)])\n",
    "                        \n",
    "                        # Calculate overfitting (train_acc - val_acc)\n",
    "                        overfitting = avg_train_acc - avg_val_acc\n",
    "\n",
    "                        print(f\"Avg Validation Accuracy: {avg_val_acc:.2f}%\")\n",
    "\n",
    "                        # Store the results for visualization\n",
    "                        results_data.append({\n",
    "                            'dropout': dropout,\n",
    "                            'momentum': momentum,\n",
    "                            'batch_size': batch_size,\n",
    "                            'weight_decay': weight_decay,\n",
    "                            'lr_scheduler': lr_scheduler,\n",
    "                            'val_acc': avg_val_acc,\n",
    "                            'train_acc': avg_train_acc,\n",
    "                            'train_loss': avg_train_loss,\n",
    "                            'val_loss': avg_val_loss,\n",
    "                            'overfitting': overfitting\n",
    "                        })\n",
    "\n",
    "                        if avg_val_acc > best_val_acc:\n",
    "                            best_val_acc = avg_val_acc\n",
    "                            best_params = params\n",
    "\n",
    "    print(f\"Best Params: {best_params}\")\n",
    "    \n",
    "    # Convert results to DataFrame for easier visualization\n",
    "    results_df = pd.DataFrame(results_data)\n",
    "    \n",
    "    return best_params, results_df\n",
    "\n",
    "# Visualization functions\n",
    "def create_visualizations(results_df, timestamp):\n",
    "    \"\"\"Create various visualizations to understand hyperparameter effects\"\"\"\n",
    "    \n",
    "    # 1. Heatmap of batch size vs dropout effect on validation accuracy\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    pivot_table = results_df.pivot_table(\n",
    "        values='val_acc', \n",
    "        index='dropout', \n",
    "        columns='batch_size', \n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    sns.heatmap(pivot_table, annot=True, cmap='viridis', fmt='.2f')\n",
    "    plt.title('Effect of Dropout and Batch Size on Validation Accuracy')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/heatmap_dropout_batchsize_{timestamp}.png\", dpi=300)\n",
    "    \n",
    "    # 2. Scatter plot of batch size vs validation accuracy colored by dropout\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for dropout in results_df['dropout'].unique():\n",
    "        subset = results_df[results_df['dropout'] == dropout]\n",
    "        plt.scatter(subset['batch_size'], subset['val_acc'], \n",
    "                   label=f'Dropout: {dropout}', alpha=0.7, s=80)\n",
    "    plt.xlabel('Batch Size')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.title('Validation Accuracy by Batch Size and Dropout')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/scatter_batchsize_accuracy_{timestamp}.png\", dpi=300)\n",
    "    \n",
    "    # 3. Bar plot for weight decay effect\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    weight_decay_effect = results_df.groupby('weight_decay')['val_acc'].mean().reset_index()\n",
    "    sns.barplot(x='weight_decay', y='val_acc', data=weight_decay_effect)\n",
    "    plt.xlabel('Weight Decay')\n",
    "    plt.ylabel('Average Validation Accuracy')\n",
    "    plt.title('Effect of Weight Decay on Validation Accuracy')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/barplot_weightdecay_{timestamp}.png\", dpi=300)\n",
    "    \n",
    "    # 4. Compare scheduler effects\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    scheduler_effect = results_df.groupby('lr_scheduler')['val_acc'].mean().reset_index()\n",
    "    sns.barplot(x='lr_scheduler', y='val_acc', data=scheduler_effect)\n",
    "    plt.xlabel('Learning Rate Scheduler')\n",
    "    plt.ylabel('Average Validation Accuracy')\n",
    "    plt.title('Effect of Learning Rate Scheduler on Validation Accuracy')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/barplot_scheduler_{timestamp}.png\", dpi=300)\n",
    "    \n",
    "    # 5. Overfitting analysis\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.scatter(results_df['train_acc'], results_df['val_acc'], alpha=0.7, s=80)\n",
    "    plt.plot([75, 100], [75, 100], 'r--', alpha=0.5)  # Diagonal line\n",
    "    plt.xlabel('Training Accuracy')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.title('Training vs Validation Accuracy (Diagonal Line Indicates No Overfitting)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/overfitting_analysis_{timestamp}.png\", dpi=300)\n",
    "    \n",
    "    # 6. Parallel coordinates plot for all parameters\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    pd.plotting.parallel_coordinates(\n",
    "        results_df, 'batch_size', \n",
    "        cols=['dropout', 'momentum', 'weight_decay', 'val_acc'],\n",
    "        colormap='viridis'\n",
    "    )\n",
    "    plt.title('Parallel Coordinates Plot of Hyperparameters')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/parallel_coordinates_{timestamp}.png\", dpi=300)\n",
    "\n",
    "    # 7. Top 10 configurations\n",
    "    top_10 = results_df.sort_values('val_acc', ascending=False).head(10)\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Create labels for x-axis\n",
    "    x_labels = []\n",
    "    for _, row in top_10.iterrows():\n",
    "        label = f\"D:{row['dropout']},M:{row['momentum']}\\nB:{row['batch_size']},W:{row['weight_decay']},S:{row['lr_scheduler']}\"\n",
    "        x_labels.append(label)\n",
    "    \n",
    "    # Create the bar plot\n",
    "    bars = plt.bar(range(len(top_10)), top_10['val_acc'], alpha=0.7)\n",
    "    plt.xticks(range(len(top_10)), x_labels, rotation=45, ha='right')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.title('Top 10 Hyperparameter Configurations')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/top10_configurations_{timestamp}.png\", dpi=300)\n",
    "\n",
    "    print(f\"Visualizations saved in plots/ directory with timestamp {timestamp}\")\n",
    "\n",
    "# Run the Experiment\n",
    "def run_experiment():\n",
    "    dataset = get_fashionmnist_data()\n",
    "\n",
    "    # Use the original parameter grid\n",
    "    param_grid = {\n",
    "        'dropout': [0.3, 0.5, 0.7],\n",
    "        'momentum': [0.8, 0.9, 0.95],\n",
    "        'batch_size': [32, 64, 128],\n",
    "        'weight_decay': [0.0, 0.0005, 0.001],\n",
    "        'lr_scheduler': ['noam', 'cosine']\n",
    "    }\n",
    "\n",
    "    # Generate timestamp for file naming\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    print(\"Starting grid search\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Run grid search\n",
    "    best_params, results_df = grid_search(dataset, SimpleCNN, param_grid, k_folds=5, epochs=5)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    execution_time = (end_time - start_time) / 3600  # hours\n",
    "    \n",
    "    print(f\"Grid search completed in {execution_time:.2f} hours\")\n",
    "    print(f\"Best Hyperparameters: {best_params}\")\n",
    "    \n",
    "    # Create visualizations\n",
    "    create_visualizations(results_df, timestamp)\n",
    "    \n",
    "    # Save the full results dataframe for later analysis\n",
    "    results_df.to_csv(f\"plots/hyperparameter_results_{timestamp}.csv\", index=False)\n",
    "    \n",
    "    print(f\"All results saved. Total execution time: {execution_time:.2f} hours\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import time\n",
    "    run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80cdcfa-011b-474c-8b99-ce81d155cead",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
